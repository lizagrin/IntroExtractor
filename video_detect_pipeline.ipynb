{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3e3c4a",
   "metadata": {},
   "source": [
    "# Автоматическое определение границ заставок и титров\n",
    "\n",
    "**Цель** — для входного видео эпизода определить две точные временные метки:\n",
    "1. **`start_main`** — первый кадр *после* вступительного логотипа/повтора.\n",
    "2. **`end_main`** — последний кадр *перед* началом финальных титров.\n",
    "\n",
    "Шаги реализации:\n",
    "1. Извлечение CLIP-эмбеддингов из кадров (опционально, с кэшированием)\n",
    "2. Построение и аугментация датасета\n",
    "3. Обучение трансформера (опционально, с кэшированием)\n",
    "4. Оценка + метрики + визуальная диагностика\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e15345",
   "metadata": {},
   "source": [
    "## 1. Настройка окружения и глобальные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd7cec4c33043b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T22:05:52.017926Z",
     "start_time": "2025-06-20T22:05:52.005928Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, json, math, glob\n",
    "import numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (precision_recall_fscore_support,\n",
    "                             confusion_matrix, ConfusionMatrixDisplay)\n",
    "import open_clip\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 110\n",
    "\n",
    "# Пути\n",
    "ROOT = pathlib.Path('.').resolve()\n",
    "DATA_DIR = ROOT / 'data'\n",
    "FRAMES_DIR = DATA_DIR / 'frames'  # Кадры с частотой 1 кадр/сек\n",
    "CLIP_DIR = DATA_DIR / 'clip_windows'  # Кэшированные окна (.npz)\n",
    "LABELS_CSV = DATA_DIR / 'labels.csv'  # Разметка временных меток\n",
    "WEIGHTS_DIR = ROOT / 'model_weights'\n",
    "WEIGHTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "BEST_WEIGHTS = WEIGHTS_DIR / 'best_clip_attention60.pth'\n",
    "\n",
    "# Воспроизводимость\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e896b8f7535a66",
   "metadata": {},
   "source": [
    "## 2. Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d1a1dba066cc45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T22:05:54.667999Z",
     "start_time": "2025-06-20T22:05:54.645964Z"
    }
   },
   "outputs": [],
   "source": [
    "def hhmmss_to_sec(ts: str) -> int:\n",
    "    # Конвертирует 'ЧЧ:ММ:СС' в секунды (целое число)\n",
    "    h, m, s = ts.split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + int(float(s))\n",
    "\n",
    "\n",
    "def sec_to_hhmmss(sec: int) -> str:\n",
    "    # Обратное преобразование к `hhmmss_to_sec`. Округляет до целых секунд\n",
    "    h, m = divmod(sec, 3600)\n",
    "    m, s = divmod(m, 60)\n",
    "    return f\"{h:02}:{m:02}:{s:02}\"\n",
    "\n",
    "\n",
    "def exists(path: pathlib.Path) -> bool:\n",
    "    # Проверяет существование файла/директории с содержимым\n",
    "    return path.exists() and any(path.iterdir()) if path.is_dir() else path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb6831b07adebd",
   "metadata": {},
   "source": [
    "## 3. Этап 1: Извлечение CLIP-эмбеддингов \n",
    "*(пропускается, если файлы .npz уже существуют)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a700ccd36c119592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T22:05:57.848069Z",
     "start_time": "2025-06-20T22:05:57.820071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings already present, skipping extraction.\n"
     ]
    }
   ],
   "source": [
    "if not exists(CLIP_DIR):\n",
    "    CLIP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def extract_clip_embeddings(frames_root: pathlib.Path = FRAMES_DIR,\n",
    "                            out_root: pathlib.Path = CLIP_DIR,\n",
    "                            batch: int = 128,\n",
    "                            window: int = 60):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model, _, _ = open_clip.create_model_and_transforms(\n",
    "        'ViT-B-32', pretrained='openai', device=device)\n",
    "    model.eval()\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224), transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                             (0.26862954, 0.26130258, 0.27577711)),\n",
    "    ])\n",
    "\n",
    "    for ep_dir in sorted(frames_root.rglob('*')):\n",
    "        if not ep_dir.is_dir():\n",
    "            continue\n",
    "        rel = ep_dir.relative_to(frames_root)\n",
    "        out_f = out_root / (str(rel).replace(os.sep, '_') + '_windows.npz')\n",
    "        if out_f.exists():\n",
    "            print(f'{rel} – cached')\n",
    "            continue\n",
    "\n",
    "        f_paths = sorted(ep_dir.glob('*.jpg'))\n",
    "        if len(f_paths) < window:\n",
    "            print(f'{rel}: <{window} frames, skipping')\n",
    "            continue\n",
    "\n",
    "        embeddings = np.empty((len(f_paths), 512), np.float32)\n",
    "        buf, idxbuf = [], []\n",
    "        for idx, fp in enumerate(tqdm(f_paths, desc=str(rel), unit='f')):\n",
    "            buf.append(preprocess(Image.open(fp)).unsqueeze(0))\n",
    "            idxbuf.append(idx)\n",
    "            if len(buf) == batch or idx == len(f_paths) - 1:\n",
    "                with torch.no_grad():\n",
    "                    feats = model.encode_image(torch.cat(buf).to(device))\n",
    "                embeddings[idxbuf] = feats.cpu().float().numpy()\n",
    "                buf, idxbuf = [], []\n",
    "\n",
    "        starts = range(0, len(embeddings) - window + 1, window)\n",
    "        windows = np.stack([embeddings[s:s + window] for s in starts])\n",
    "        np.savez_compressed(out_f, windows=windows, start_indices=np.array(list(starts)))\n",
    "        print(f'Saved {windows.shape[0]} windows ➜ {out_f.name}')\n",
    "\n",
    "\n",
    "if not any(CLIP_DIR.glob('*_windows.npz')):\n",
    "    print('Extracting CLIP embeddings …')\n",
    "    extract_clip_embeddings()\n",
    "else:\n",
    "    print('Embeddings already present, skipping extraction.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd9504d95d471c0",
   "metadata": {},
   "source": [
    "## 4. Создание датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a4ced1170efc9dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T22:06:04.347924Z",
     "start_time": "2025-06-20T22:06:04.321925Z"
    }
   },
   "outputs": [],
   "source": [
    "class VideoWindowDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Датасет для окон видео. Каждый элемент:\n",
    "    - Окно 60×512 (CLIP-эмбеддинги)\n",
    "    - Бинарная маска 60×1 (1=заставка/титры, 0=основное содержание)\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 root_npz=CLIP_DIR,\n",
    "                 labels_csv=LABELS_CSV,\n",
    "                 split='train',\n",
    "                 test_shows=('show2',),  # Сериалы для тестирования\n",
    "                 augment=False):\n",
    "        self.root = pathlib.Path(root_npz)\n",
    "        self.labels_df = pd.read_csv(labels_csv)\n",
    "\n",
    "        # Словарь эпизод -> (start_main, end_main) в секундах\n",
    "        self.meta = {pathlib.Path(row.file).stem: (hhmmss_to_sec(row.start_main),\n",
    "                                                   hhmmss_to_sec(row.end_main))\n",
    "                     for _, row in self.labels_df.iterrows()}\n",
    "\n",
    "        self.items = []\n",
    "        for p in self.root.glob('*.npz'):\n",
    "            show = p.name.split('_')[0]\n",
    "            # Разделение на train/val по сериалам (§4.1.6)\n",
    "            if (split == 'train' and show in test_shows) or \\\n",
    "                    (split == 'val' and show not in test_shows):\n",
    "                continue\n",
    "\n",
    "            with np.load(p) as npz:\n",
    "                win, idxs = npz['windows'], npz['start_indices']\n",
    "            vid_key = '_'.join(p.stem.split('_')[1:-1])\n",
    "            s, e = self.meta[vid_key]\n",
    "\n",
    "            # Генерация масок для каждого окна\n",
    "            for w, idx in zip(win, idxs):\n",
    "                t = np.arange(idx, idx + 60)\n",
    "                y = ((t < s) | (t >= e)).astype(np.float32)\n",
    "                self.items.append((w.astype(np.float32), y))\n",
    "\n",
    "        self.augment = augment  # Флаг аугментации\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.items[i]\n",
    "        if self.augment:\n",
    "            x, y = self._augment(x, y)\n",
    "        return torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "    # Аугментация\n",
    "    @staticmethod\n",
    "    def _augment(x, y):\n",
    "        # Случайный сдвиг до ±5 секунд\n",
    "        shift = np.random.randint(-5, 6)\n",
    "        if shift:\n",
    "            x = np.roll(x, shift, 0)\n",
    "            y = np.roll(y, shift)\n",
    "        # Замена случайных кадров (10-30%)\n",
    "        mask = np.random.rand(60) < np.random.uniform(0.1, 0.3)\n",
    "        x[mask] = x[np.random.permutation(60)[mask]]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2614026d39a65e71",
   "metadata": {},
   "source": [
    "## 5. Модель — *ClipAttention60*  *(§3.3–3.5 статьи)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c77ea2accbf76a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T22:06:08.783231Z",
     "start_time": "2025-06-20T22:06:08.764234Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClipAttention60(nn.Module):\n",
    "    \"\"\"Трансформер с многоголовым вниманием для окон 60×512.\n",
    "    Возвращает 60 сигмоидных вероятностей p(t)=P[заставка/титры в секунду t].\"\"\"\n",
    "\n",
    "    def __init__(self, d_model=512, nhead=16, nlayers=16, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.pos = nn.Parameter(torch.randn(60, d_model))  # Обучаемая позиционная кодировка\n",
    "\n",
    "        # Трансформер-энкодер с 16 слоями и 16 головами (§3.4)\n",
    "        enc_layer = nn.TransformerEncoderLayer(d_model, nhead,\n",
    "                                               4 * d_model, dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n",
    "\n",
    "        # 60 независимых классификаторов (§3.5)\n",
    "        self.classifiers = nn.ModuleList([nn.Linear(d_model, 1) for _ in range(60)])\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):  # (B,60,512)\n",
    "        h = self.encoder(x + self.pos)  # (B,60,512)\n",
    "        logits = torch.cat([cls(h[:, t]) for t, cls in enumerate(self.classifiers)], 1)\n",
    "        return self.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b498b9b040549f1",
   "metadata": {},
   "source": [
    "## 6. Этап 2: Обучение модели \n",
    "*(пропускается, если веса уже обучены)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e950d94ee2d4014",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-06-20T22:06:27.698768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение трансформера...\n"
     ]
    }
   ],
   "source": [
    "if not BEST_WEIGHTS.exists():\n",
    "    print('Обучение трансформера...')\n",
    "\n",
    "\n",
    "    def train_model(epochs=16, batch=8):\n",
    "        # Процедура обучения \n",
    "        train_ds = VideoWindowDataset(split='train', augment=True)\n",
    "        val_ds = VideoWindowDataset(split='val', augment=False)\n",
    "        train_loader = DataLoader(train_ds, batch, shuffle=True, num_workers=4)\n",
    "        val_loader = DataLoader(val_ds, batch, shuffle=False, num_workers=4)\n",
    "\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        model = ClipAttention60().to(device)\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=5e-5)  # Оптимизатор Adam\n",
    "        criterion = nn.BCELoss()  # Бинарная кросс-энтропия\n",
    "\n",
    "        best = math.inf  # Лучшее значение loss\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            for phase, loader, train in [('train', train_loader, True),\n",
    "                                         ('val', val_loader, False)]:\n",
    "                running = 0\n",
    "                n = 0\n",
    "                model.train(train)\n",
    "                for x, y in loader:\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                    with torch.set_grad_enabled(train):\n",
    "                        p = model(x)\n",
    "                        loss = criterion(p, y)\n",
    "                        if train:\n",
    "                            loss.backward()\n",
    "                            optim.step()\n",
    "                            optim.zero_grad()\n",
    "                    running += loss.item() * x.size(0)\n",
    "                    n += x.size(0)\n",
    "                print(f\"Эпоха {epoch:02} {phase:<5} loss={running / n:.4f}\")\n",
    "\n",
    "            # Сохранение лучшей модели\n",
    "            if running / n < best:\n",
    "                best = running / n\n",
    "                torch.save(model.state_dict(), BEST_WEIGHTS)\n",
    "                print('Сохранена лучшая модель')\n",
    "\n",
    "\n",
    "    train_model()\n",
    "else:\n",
    "    print('Обученные веса обнаружены, обучение пропущено.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2850f9",
   "metadata": {},
   "source": [
    "## 7. Этап 3: Оценка модели и визуальная диагностика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127aa3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, torch, pathlib, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.ndimage import median_filter, uniform_filter1d\n",
    "\n",
    "\n",
    "# служебные функции \n",
    "def hhmmss_to_sec(ts: str) -> float:\n",
    "    # Перевод времени 'HH:MM:SS(.sss)' в секунды (float)\n",
    "    h, m, s = ts.split(\":\")\n",
    "    return int(h) * 3600 + int(m) * 60 + float(s)\n",
    "\n",
    "\n",
    "def mad(x: np.ndarray) -> float:\n",
    "    # Median Absolute Deviation— устойчивая оценка разброса\n",
    "    med = np.median(x)\n",
    "    return np.median(np.abs(x - med))\n",
    "\n",
    "\n",
    "def key_npz(p: pathlib.Path) -> str:\n",
    "    # Переименование файла `show_ep_windows.npz` → уникальный идентификатор\n",
    "    return \"_\".join(p.stem.split(\"_\")[1:-1])\n",
    "\n",
    "\n",
    "def key_csv(path: str) -> str:  # labels path → id\n",
    "    return pathlib.Path(path).stem\n",
    "\n",
    "\n",
    "def find_first_block(mask: np.ndarray) -> int:\n",
    "    \"\"\"Возвращает индекс начала первого длинного блока из ≥5 едиц\n",
    "    (intro) за которым следует ≥10 нуля (основное содержание).\"\"\"\n",
    "    run1 = run0 = 0\n",
    "    for i, m in enumerate(mask):\n",
    "        if m:\n",
    "            run1 += 1\n",
    "            run0 = 0\n",
    "        else:\n",
    "            run0 += 1\n",
    "            if run1 >= 5 and run0 >= 10:\n",
    "                return i - run0 + 1\n",
    "    return 0  # если не найдено\n",
    "\n",
    "\n",
    "def find_last_block(mask: np.ndarray) -> int:\n",
    "    # Аналогично `find_first_block`, но ищем с конца\n",
    "    run1 = run0 = 0\n",
    "    pos = len(mask) - 1\n",
    "    for i in range(len(mask) - 1, -1, -1):\n",
    "        if mask[i]:\n",
    "            run1 += 1\n",
    "            run0 = 0\n",
    "        else:\n",
    "            run0 += 1\n",
    "            if run1 >= 5 and run0 >= 10:\n",
    "                pos = i + run0 - 1\n",
    "                break\n",
    "    return pos\n",
    "\n",
    "\n",
    "# 1. загрузка обученной сети\n",
    "BEST_WEIGHTS = pathlib.Path(\"model_weights/best_clip_attention60.pth\")\n",
    "model = ClipAttention60()\n",
    "model.load_state_dict(torch.load(BEST_WEIGHTS, map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "# 2. загрузка разметки\n",
    "labels = pd.read_csv(\"data/labels.csv\")\n",
    "labels[\"key\"] = labels[\"file\"].apply(key_csv)\n",
    "labels = labels.set_index(\"key\")\n",
    "\n",
    "# 3. обход всех эпизодов\n",
    "root = pathlib.Path(\"data/clip_windows\")\n",
    "results = []  # будем складывать (key, s_pred, s_true, e_pred, e_true, p, thr_s, thr_e)\n",
    "\n",
    "for f in sorted(root.glob(\"*_windows.npz\")):\n",
    "    key = key_npz(f)\n",
    "    if key not in labels.index:\n",
    "        print(f\"{key} пропущен — нет разметки\")\n",
    "        continue\n",
    "\n",
    "    data = np.load(f)\n",
    "    windows = data[\"windows\"]  # (N, 60, 512)\n",
    "    starts = data[\"start_indices\"]  # (N,)\n",
    "\n",
    "    # если до конца сериала осталось <30 с, добавляем «хвост» из нулей\n",
    "    total_secs = starts[-1] + windows.shape[1]\n",
    "    labelled_end = hhmmss_to_sec(labels.loc[key, \"end_main\"])\n",
    "    if labelled_end + 30 > total_secs:\n",
    "        windows = np.concatenate([windows, np.zeros((1, 60, 512), np.float32)], axis=0)\n",
    "\n",
    "    # прогноз вероятности p(t) для каждого кадра \n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        for w in torch.from_numpy(windows):\n",
    "            probs.append(model(w.unsqueeze(0)).squeeze(0).numpy())\n",
    "    p = np.concatenate(probs)  # (T,)\n",
    "\n",
    "    # сглаживаем: mean(3 с) → median(7 с)\n",
    "    p = uniform_filter1d(p, size=3)\n",
    "    p = median_filter(p, size=7)\n",
    "\n",
    "    # адаптивные пороги \n",
    "    base = np.median(p)\n",
    "    spread = mad(p)\n",
    "    thr_s = base + 2 * spread  # строгий порог для заставки\n",
    "    thr_e = np.percentile(p, 70)  # мягче для титров\n",
    "\n",
    "    mask_s = p > thr_s\n",
    "    mask_e = p > thr_e\n",
    "\n",
    "    # предсказанные границы \n",
    "    s_pred = find_first_block(mask_s)\n",
    "    tail = int(len(mask_e) * 0.50)  # анализируем только вторую половину\n",
    "    e_pred = tail + find_last_block(mask_e[tail:])\n",
    "\n",
    "    # истинные границы\n",
    "    s_true = hhmmss_to_sec(labels.loc[key, \"start_main\"])\n",
    "    e_true = hhmmss_to_sec(labels.loc[key, \"end_main\"])\n",
    "\n",
    "    results.append((key, s_pred, s_true, e_pred, e_true, p, thr_s, thr_e))\n",
    "\n",
    "# 4. метрики MAE \n",
    "mae_start = np.mean([abs(sp - st) for _, sp, st, _, _, _, _, _ in results])\n",
    "mae_end = np.mean([abs(ep - et) for _, _, _, ep, et, _, _, _ in results])\n",
    "print(f\"\\nСредняя абсолютная ошибка:  начало = {mae_start:.2f}с,  конец = {mae_end:.2f}с\\n\")\n",
    "\n",
    "# 5. вывод + сохранение графиков\n",
    "pathlib.Path(\"plots_2\").mkdir(exist_ok=True)\n",
    "for key, sp, st, ep, et, p, ts, te in results:\n",
    "    print(f\"{key:38}   start {sp:4}/{st:4}с   |   end {ep:4}/{et:4}с\")\n",
    "    # отрисуем график\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    t = np.arange(len(p))\n",
    "    plt.plot(t, p, lw=1, label='p(t)')\n",
    "    plt.axhline(ts, color='C2', ls='--', label='порог заставки')\n",
    "    plt.axhline(te, color='C3', ls='--', label='порог титров')\n",
    "    plt.axvline(sp, color='C2')\n",
    "    plt.axvline(st, color='C2', ls=':')\n",
    "    plt.axvline(ep, color='C3')\n",
    "    plt.axvline(et, color='C3', ls=':')\n",
    "    plt.title(key)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots_2/{key}.png\", dpi=120)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re, pathlib, numpy as np\n",
    "\n",
    "# Проверяем, что вероятность рассчитана раз в секунду\n",
    "assert len(p) == starts[-1] + windows.shape[1], \\\n",
    "    \"Длина p не совпадает с числом секунд – проверьте fps!\"\n",
    "\n",
    "SAVE_DIR = pathlib.Path('data/video_probs')\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "episode_id = re.sub(r'\\.npz$', '', f.name).replace('_windows', '')  # show1_s01e02\n",
    "np.save(SAVE_DIR / f'p_video_{episode_id}.npy', p.astype('float32'))\n",
    "print(f'✔ Видео-вероятности сохранены: {SAVE_DIR / f\"p_video_{episode_id}.npy\"}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45d151a57aedd033"
  },
  {
   "cell_type": "markdown",
   "id": "18ba9b4b",
   "metadata": {},
   "source": [
    "## 8. Заключение и дальнейшие шаги\n",
    "\n",
    "**Результаты:**\n",
    "- Конвейер CLIP+Attention60 достигает F1 >90% с точностью до секунды (§4.2)\n",
    "- Модель эффективна для разных типов контента (фильмы, сериалы, короткие видео)\n",
    "- Оптимизация под ONNX/TensorRT позволяет обработку в реальном времени (§6)\n",
    "\n",
    "**Ограничения (§8.1):**\n",
    "- Трудности с наложенными титрами\n",
    "- Ошибки в сложных художественных переходах\n",
    "- Проблемы с короткими заставками (<5 сек)\n",
    "\n",
    "**Направления развития (§8.2):**\n",
    "1. Мультимодальное обучение (аудио, субтитры)\n",
    "2. Использование управляющих токенов для фокусировки на ключевых областях\n",
    "3. Расширение датасета (пользовательский контент, мультиязычность)\n",
    "4. Улучшение интерпретируемости предсказаний\n",
    "5. Применение для других задач: рекламные паузы, границы сцен\n",
    "\n",
    "**Практическое применение:**\n",
    "- Автоматическое пропуск заставок в стриминговых платформах\n",
    "- Индексация видеоархивов\n",
    "- Генерация видеосаммари\n",
    "- Контентная модерация"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
